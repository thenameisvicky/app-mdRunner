---
title: Deep dive into v8 - JS compiler engine
date: 2025-11-16
---

## Compiler Engine

## v8 Internals Overview

- **Engine overview**
  - v8 is Google's Javascript & webAssembly engine.
    1. Used in chrome, Edge, Opera - browser side.
    2. Node.js, deno - server side.
    3. Electron Apps - desktop.
  - It is written in C++, it's job is to
    1. Parse your JS code (source -> **A**bstract **S**yntax **T**ree).
    2. Compile it into machine code.
    3. Allocate memory (heap and stack).
    4. Manage garbage collection - GC.
    5. Execute effciently through optimizing JIT compilers - Ignition + TurboFan.
- **Architecture Theory**
  - v8's heap isn't a single continous blob, It is segmented into spaces, each with its own allocator, page size and Garbage collection policy / strategy.
  - v8 divides the heap into different spaces, each space is optimized for a different kind of object or allocation behavior.
  - Small short lived objects behave differently from large, long-lived ones.
  - Specialized collectors can be faster and use less memory if they target only certain objects.
  - **New Space**
    - New space is also called as Eden space, every single object allocation frist gets it's memory space here.
    - When Ededn space overflows it triggers Minor GC - one of the strategies followed by the Garbage collector of v8.
    - This Minior GC will move the Live objects - objects which are needed or rechable from current function execution to another space within New space, likewise a object that survies will be moved into Old space.
    - V8 uses dynamic survivor age threshold, not a fixed number.
  - **Old Space**
    - Old space is for Long lived objects - objects in module level and closures exists here these are collected by **Major GC** (Mark-sweep/Mark-compact).
    - Major GC process is more expensive this **Marks** reachable objects, **Sweep** unrechable ones and **Compact** the live Objects together to remove fragments of Sweeped objects.
    - Even though this runs less often this process is expensive because it touches more memory, v8 optimizes it heavily with incremental and concurrent marking.
  - **Code Space**
    - This is where the JIT-compiled machine code generated by v8 is stored.
    - Code needs executable memory permissions (W^X), which data objects should not have, that is why compiled code is in seperate space which is not sandboxed.
    - W^X - Write or Execute
      - When writing code → page is Writable + Non-executable.
      - When executing code → page is Executable + Non-writable.
    - Seperating prevents security risks (ex: writing data into executable pages, malicious data inputs from UI).
    - Garbage collection here is compacting - this can't move executing code.
  - **Map Space**
    - Holds the **Hidden classes** many maps which describes the internal structure of the object shapes - every object that is in Memory.
    - Mark-Compact is the GC strategy used.
    - v8 does not use dynamic dictionaries for every objects it uses a hidden classes to make property access fast.
    - Each Js object points to a map describing it's structure.
    - Since these don't change often, they live longer and are compacted efficiently.
  - **Large Object Space**
    - Holds big objects such as large arrays or buffers.
    - Page size is variable each objects gets it's own chunk.
    - Only Mark sweep GC strategy not anything else.
    - No compacting and large objects stored here because moving large object from New -> Old is very much expensive.
    - Contexts states, redux stores, slices stored here.
    - These are just **Marked** and **Sweeped** when they are unreachable.
    - As this space won't get Compacted, this will get fragmented but this is bearable because moving this is much expensive.
  - Each page maintains a page list, where each page holds object allocations and metadata like mark bits and free lists.
  - Key concept is objects just move in **New space** (Minor GC) but they don't move in **Large object space** (Mark sweep GC) that is why you can't use direct memory offsets across objects.
- **Memory Regions**
  - **Call Stack**
      1. Fast, structured, predictable Memory (function frames, primitives, call context), simple words execution stuffs goes here.
      2. Call stack is used for functoin calls, local variables and control flow.
      3. It's small and fast.
      4. Each function call creates a stack frame which contains
          - Return address (where to go after call).
          - Local variables.
          - Arguments passed.
          - Execution context pointer like scope chain.
      5. When function finishes (returns) the frame is popped.
      6. If recursion or infinite loop -> "Maximum call stack size exceeded" error thrown and execution stopped.
      7. Stack is linear data structure LIFO - Last In First Out so no GC needed.
  - **Memory Heap**
      1. Flexible, dynamic memory (objects, arrays, closures, functions), all dynamic variables goes here.
      2. Memory heap is the space where all reference-type data lives this is managed by Garbage Collector.
- **Generational Garbage Collection**
  - v8 uses a generational GC strategy, based on the empirical rule that most object die young.
  - **Minor GC (Young Generation)**
    - Targets the New Space-**Minor GC** (Eden + semi-space).
    - Fast copying collector
      - Copy live objects `from-space` -> `to-space`.
      - Swap pointers.
      - Dead objects just vanish their space is not copied.
      - After a few cycle, surviving objects get promoted to Old Space-**Major GC**.
  - **Major GC (Old Generation)**
    - Runs less often but is more expensive.
    - Performs mark, sweep and compact.
      1. **Mark:** Traverses from roots (globals, stack, refs) **marking** reachable objects.
      2. **Sweep:** Reclaims **unmarked** memory.
      3. **Compact:** Moves live objects together to reduce fragmentation(breaking of objects).
    - Old-space objects rarely move, it only moved during **Compact** same concept used in database collection/tables.
  - **Incremental and Concurrent GC**
    - Incremental Marking: Breaks large mark phases into small slices to avoid blocking JS.
    - Concurrent sweeping: Sweeping happens off the main thread.
    - Idle-time GC: When chrome detects frame idle time, it runs GC tasks in background.
    - GC do not delete the memory from OS, it makes sure that the memory is available for reuse.
- **Memory Allocation Pipeline**
  - **Function Frame -> Stack** - Primitive values , references.
  - **Object Creation -> Heap allocation** - Allocator picks the current space.
  - **Fast Allocation Path**
    - v8 uses bump pointer allocation in the New Space.
    - Super fast `top += size;`
  - If no space left **Minor GC** is triggred.
- **Objects shapes, Hidden Classes and inline classes**
  - Memory effiency and JIT speed depnds on object shape and stability
  - There is this concept called **Hidden Classes**, when you create an object v8 assigns it in a hidden *map* - a structure describing it's property layout.
  - Adding or deleting properties changes it's shape which eventually ends up as a new **Hidden class**.
  - Infinite caches (ICs) stores lookups for hot properites based on access pattern.
  - Stable shapes results in fewer transitions which eventually offers faster property access and better memory allocation.
  - Best practice is to initialize object fields in same order.This allows shape sharing and hidden class churn.
- **JIT Memory spaces**
  - Compiled code and runtime metadata lives in specialized space.
  - Code space - Generated native instructions by **TurboFan**.
  - Read only space - Immutable built-ins, constrains frozen objects.
  - External Memory - Buffers allocated outside v8 (Ex: Array buffer, node buffer).
  - External memory is tracked via **ExternalBackingStore** so that GC will know when it's safe to release.
- **GC Triggers and Performance Heuristics**
  - v8 doesn't run GC Arbitrarily -- it uses adaptive heuristics.
  - Memory pressure on OS.
  - Idle time budget which is detected via chromium browser's scheduler.
  - Allocation rate if allocation is too fast GC will run frequently.
  - If a object is promoted to to old space from new space then it will trigger major GC.
  - witness with below commands `--max-old-space-size=4096  # 4GB limit`, `--trace-gc # Log GC activity`, `--trace-gc-verbose # Detailed stats`.
- **Memory leaks and Retained References**
  - Typical memory leaks in Js corresponds to unreleased references that prevent GC. Breif explanations about memory leak patters have listed below.
    - **Global variables** (Ex: ) these persist for app lifetime to prevent this use local scope or `let`.
    - **Detached DOM nodes** elements removed but still referenced, nullify reference after removal of the objects.
    - **Closures capturing large objects** retain scoped values, use `WeakRefs` or explicit cleanup.
    - **Event listeners on dead node** still alive in memory, Remove listeners on unmount.
    - **Caches without eviction** when `Map/Set` grows, use `WeakMap` or `WeakRef` instead.
    - **Tools for v8 memory analysis**
      1. **Chrome DevTools -> Memory tab** - Heap snapshots, allocation timeline visualize retained objects.
      2. **Node.js --inspect** - Attach chrome debugger to Node, works same as browser.
      3. **--trace-gc logs** - GC pause time, memory before/after, good for server profiling.
      4. **heapdump (Node module)** - Captures heap at runtime, Analyze leaks offline.
      5. **v8 Inspector Protocol** - Access memory stats programmatically for custom profiling.
  - **Typical Memory Lifespan**
    - Function creates object → goes to New Space.
    - Function returns, reference lost → object collected in Minor GC.
    - If reference survives long → moved to Old Space.
    - Large data (image buffers, 10MB+ arrays) → Large Object Space.
    - Compiled function code → Code Space.
    - Hidden classes (object shapes) → Map Space.

## WebAssembly (WASM) in the Browser

- v8 can execute **WebAssembly** — a compact binary format that runs near-native speed.
- WebAssembly runs inside the same v8 heap, but its memory is managed manually.
- `WebAssembly.Memory` is a growable linear buffer.
- You manage its allocations manually (malloc-style).
- GC ignores WASM memory — it’s treated as external memory
- Compiled from C, C++, or Rust.
- Executes alongside JS in v8.
- Ideal for compute-heavy tasks like image processing or ML inference.

## Upcoming Topics

- Rendering engine deep internals - blink specific concepts.
- GPU pipeline specifics - sika, viz, surfaces + frame sink.
- Javascript engine integration details - Oilpan GC in blink for DOM.

Questions -

1. CUDA is the software that communicates with GPU to paint the pixels ? from renderer to GPU is this acts as middleware ?
2. Renderer Process Internals, Renderer process contains, Blink (DOM engine), Layout engine, Compositor, V8 engine, JS runtime ,Web APIs (implemented in Blink), Garbage collector, Execution contexts (one per frame), Isolated worlds (for content scripts),
Renderer executes web code → V8 interprets JS → bytecode → optimizing compiler → actual machine code.
3. How Abstract syntax tree looks and how Typescript converted into compiled javascript with exmaples.
